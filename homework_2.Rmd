---
title: "Homework 1"
author: "Mingyin Wang"
date: 2024-09-28
output: github_document
---

```{r, echo = FALSE}
library(tidyverse)
library(readxl)
library(haven)
```
## Problem 1

#creates the the dataframe
```{r}
nyc_trans_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c"))  |>
  janitor::clean_names()  

```

# clean the dataframe
```{r}
clean_nyc_trans_df = nyc_trans_df |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

trans_row = nrow(clean_nyc_trans_df)
trans_col = ncol(clean_nyc_trans_df)
```
This dataset contains information about subway entrances and exits in the NYC Transit system, with key variables including the line, station name, station latitude and longitude, routes served, whether entry is allowed at a specific entrance, the presence of vending machines, entrance type, and ADA (Americans with Disabilities Act) compliance. 

I selected only relevant columns, such as line, station name, station latitude/longitude, routes, entry, vending, entrance type, and ADA compliance.
I standardized column names using `janitor::clean_names()` to ensure consistency.
I converted the entry variable from character format YES or NO to a logical variable TRUE or FALSE to make it easier to work with by using `ifelse()`. 

After the data cleaning process, it is now tidy. 

After cleaning, the dataset contains `r trans_row`rows and `r `trans_col` columns. 

# creates distinct stations dataframe
```{r}
distinct_stations = clean_nyc_trans_df |> 
  distinct(station_name, line) |> 
  count()

```
There are `r distinct_stations` distinct stations. 

# ADA compliant stations dataframe
```{r}
ada_compliant_stations = clean_nyc_trans_df |> 
  filter(ada == TRUE) |> 
  distinct(station_name, line) |> 
  count()
```

There are `r ada_compliant_stations` ADA compliant stations. 

#proportion of no vending entry
```{r}
no_vending_entry_proportion =  
  clean_nyc_trans_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```
The proportion of stations without vending that allow entry is `r no_vending_entry_proportion`.

#Reformat data so that route number and route name are distinct variables. 
```{r}

A_route = clean_nyc_trans_df |>
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct() 


A_ada= clean_nyc_trans_df |>
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A" & ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

There are 60 distinct stations serve the A train. 

Of the 60 stations that serve the A train, 17 are ADA compliant



## Problem 2

#load and clean mr trash wheel dataset.
```{r}
mr_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1, na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
    sports_balls = as.integer(round(sports_balls)), 
    source = "Mr. Trash Wheel"
  )
mr_trash_wheel
```

#load and clean prof trash wheel dataset
```{r}
prof_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1, na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
   year = as.character(year), 
    source = "Professor Trash Wheel"
  )
prof_trash_wheel
```


#load and clean Gwynnda trash wheel dataset

```{r}
gwynnda_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1,na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
   year = as.character(year), 
    source = "Gwynnda Trash Wheel"
  )
gwynnda_trash_wheel
```

#combine three dataset
```{r}
trash_wheel_data = 
  bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel) |> 
  relocate(source)

trash_wheel_data
```
The combined dataset includes observations from three different Trash Wheels: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. After importing and cleaning the data from three separate Excel sheets, we added an additional variable, `source`, to distinguish between the sources. The dataset contains `r nrow(trash_wheel_data)` rows and `r ncol(trash_wheel_data)`columns.

The key variables are,:`date`, `weight_tons`,`volume_cubic_yards`, `plastic_bottles`, `polystyrene`,`cigarette_butts`, `glass_bottles`
, `plastic_bags`, `wrappers`, `glass_bottles`, `plastic_bags`, `wrappers` and `sports_balls`. The `weight_tons` shows that the weight of the trash collected on that specific date. Rest of the key varaibles represent the amount of the kinds of trash that are collected on the specific date.
total weight collected by prof trash wheel

```{r}
total_weight_pro = 
  trash_wheel_data |>
  filter(source == "Professor Trash Wheel") |> 
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))
total_weight_pro
```
The total weight collected by prof trash wheel is `r total_weight_pro` tons.

#Total cigarette butts collected by Gwynnda in June 2022
```{r}
tot_butts_june_2022=
   trash_wheel_data |> 
    filter(source == "Gwynnda Trash Wheel", month =="June", year == "2022") |> 
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))

tot_butts_june_2022
```
The total cigarette butts collected by Gwynnda in June 2022 is `r tot_butts_june_2022` tons. 

## Problem 3

#load the dataset and did some cleaning

```{r}
bakers_df = read_csv("./data/bakers.csv", na = c("NA", ".", "", "N/A")) |> 
  janitor::clean_names() |>
  mutate(
    series = as.numeric(series), 
    baker_name = str_to_lower(str_trim(baker_name)), 
     baker =  word(baker_name, 1)
  )


bakes_df = read_csv("./data/bakes.csv", na = c("NA", ".", "", "N/A")) |> 
  janitor::clean_names() |>
  mutate(
    series = as.numeric(series),
    episode = as.numeric(episode), 
    baker = str_to_lower(str_trim(baker)),  
    baker = ifelse(baker == '"jo"', "joanne", baker)  
  )


results_df = read_csv("./data/results.csv", na = c("NA", ".", "", "N/A"), skip = 2) |> 
  janitor::clean_names() |>
  mutate(
    series = as.numeric(series),
    episode = as.numeric(episode), 
    baker = str_to_lower(str_trim(baker))  
  )
bakes_df
results_df
bakers_df
```
I standardize column names by using `janitor::clean_names()`. The `series` and`episode` columns are converted to numeric to ensure correct data types for furture analysis. There are first names and last name for bakers in baker_df, but there are only first names in the other 2 dataframes. Then, I created another column to that only contains first name so that it will be easier to merge datasets. I found out that Jo is actually Joanne in bakes_df, since in the original bakes_df, there is a baker "Jo", but there is no "Jo" in the result_df. Then, I checked that "Jo" and Joanne 's episode and series match in two different data frames. Then, I change "Jo" to Joanne in the bakes_df. 
 
#use `anti_join()` to compare three datasets

```{r}
anti_join(bakes_df, results_df, by = c("series", "episode", "baker"))
anti_join(results_df, bakes_df, by = c("series", "episode", "baker"))
anti_join(bakers_df, bakes_df, by = c("baker", "series"))
anti_join(bakes_df, bakers_df, by = c("baker", "series"))
anti_join(results_df, bakers_df, by = c("series", "baker"))
anti_join(bakers_df, results_df, by = c("series","baker"))
```



#merge all three
```{r}
final_df = results_df |>
  left_join(bakes_df, by = c("series", "episode", "baker")) |>
  left_join(bakers_df, by = c("series", "baker")) 
final_df
```





#star bakers and winners from series 5 to 10
```{r}
star_bakers = final_df |> 
  filter(series >= 5 & series <= 10) |> 
  filter(result == "STAR BAKER" | result == "WINNER") |> 
  select(series, episode, baker, result)

star_bakers
```

Findings: From series 5 to 10, the all the winners are from episode 10. 

#load and clean the viewership data 

```{r}
viewers_df = read_csv("./data/viewers.csv", na = c("NA", ".", "", "N/A")) |> 
  janitor::clean_names()

tidy_viewers_df = viewers_df |> 
  pivot_longer(
    cols = starts_with("series"),  
    names_to = "season",  
    values_to = "viewers",  
     names_prefix = "series_" 
  ) |> 
  mutate(
    season = as.numeric(season) 
  )

head(tidy_viewers_df, 10)
```

# find the avg viewers in series 1 

```{r}

avg_viewers_season_1 <- tidy_viewers_df |> 
  filter(season == 1) |>  
  summarise(avg_viewers = mean(viewers, na.rm = TRUE))
  avg_viewers_season_1
```
# find the avg viewers in series 5
```{r}

avg_viewers_season_5 <- tidy_viewers_df |> 
  filter(season == 5) |>  
  summarise(avg_viewers = mean(viewers, na.rm = TRUE))
  avg_viewers_season_5
  
```
The average viewership in Season 1 is `r avg_viewers_season_1` 
The average viewership in Season 5 is `r avg_viewers_season_5` 