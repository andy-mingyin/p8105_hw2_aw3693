---
title: "Homework 1"
author: "Mingyin Wang"
date: 2024-09-28
output: github_document
---

```{r, echo = FALSE}
library(tidyverse)
library(readxl)
library(haven)
```
## Problem 1

creates the the dataframe
```{r}
nyc_trans_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c"))  |>
  janitor::clean_names()  

```

```{r}
clean_nyc_trans_df = nyc_trans_df |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

trans_row = nrow(clean_nyc_trans_df)
trans_col = ncol(clean_nyc_trans_df)
```
This dataset contains information about subway entrances and exits in the NYC Transit system, with key variables including the line, station name, station latitude and longitude, routes served, whether entry is allowed at a specific entrance, the presence of vending machines, entrance type, and ADA (Americans with Disabilities Act) compliance. 

I selected only relevant columns, such as line, station name, station latitude/longitude, routes, entry, vending, entrance type, and ADA compliance.
I standardized column names using `janitor::clean_names()` to ensure consistency.
I converted the entry variable from character format YES or NO to a logical variable TRUE or FALSE to make it easier to work with by using `ifelse()`. 

After the data cleaning process, it is now tidy. 

After cleaning, the dataset contains `r trans_row`rows and `r `trans_col` columns. 

distinct stations
```{r}
distinct_stations = clean_nyc_trans_df |> 
  distinct(station_name, line) |> 
  count()

```
There are `r distinct_stations` distinct stations. 

ADA compliant stations 
```{r}
ada_compliant_stations = clean_nyc_trans_df |> 
  filter(ada == TRUE) |> 
  distinct(station_name, line) |> 
  count()
```

There are `r ada_compliant_stations` ADA compliant stations. 


```{r}
no_vending_entry_proportion =  
  clean_nyc_trans_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```
The proportion of stations without vending that allow entry is `r no_vending_entry_proportion`.

Reformat data so that route number and route name are distinct variables. 
```{r}

A_route = clean_nyc_trans_df |>
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct() 


A_ada= clean_nyc_trans_df |>
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A" & ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

There are 60 distinct stations serve the A train. 

Of the 60 stations that serve the A train, 17 are ADA compliant



## Problem 2
load and clean mr trash wheel dataset
```{r}
mr_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
    sports_balls = as.integer(round(sports_balls)), 
    source = "Mr. Trash Wheel"
  )
mr_trash_wheel
```

load and clean prof trash wheel dataset
```{r}
prof_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
   year = as.character(year), 
    source = "Professor Trash Wheel"
  )
prof_trash_wheel
```


load and clean Gwynnda trash wheel dataset

```{r}
gwynnda_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(
   year = as.character(year), 
    source = "Gwynnda Trash Wheel"
  )
gwynnda_trash_wheel
```

combine three dataset
```{r}
trash_wheel_data = 
  bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel) |> 
  relocate(source)
trash_wheel_data
```

total weight collected by prof trash wheel

```{r}
total_weight_pro = 
  trash_wheel_data |>
  filter(source == "Professor Trash Wheel") |> 
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))
total_weight_pro
```
The total weight collected by prof trash wheel is `r total_weight_pro` tons.

Total cigarette butts collected by Gwynnda in June 2022
```{r}
tot_butts_june_2022=
   trash_wheel_data |> 
    filter(source == "Gwynnda Trash Wheel", month =="June", year == "2022") |> 
  summarize(total_weight = sum(weight_tons, na.rm = TRUE))

tot_butts_june_2022
```
The total cigarette butts collected by Gwynnda in June 2022 is `r tot_butts_june_2022` tons. 

## Problem 3
load the dataset and did some cleaning

```{r}
bakers_df = read_csv("./data/bakers.csv", na = c("NA", ".", "", "N/A")) |> 
  janitor::clean_names() |>
  mutate(
    series = as.numeric(series), 
    baker_name = str_to_lower(str_trim(baker_name)), 
     baker =  word(baker_name, 1)
  )


bakes_df = read_csv("./data/bakes.csv", na = c("NA", ".", "", "N/A")) |> 
  janitor::clean_names() |>
  mutate(
    series = as.numeric(series),
    episode = as.numeric(episode), 
    baker = str_to_lower(str_trim(baker)),  
    baker = ifelse(baker == '"jo"', "joanne", baker)  
  )


results_df = read_csv("./data/results.csv", na = c("NA", ".", "", "N/A"), skip = 2) |> 
  janitor::clean_names() |>
  mutate(
    series = as.numeric(series),
    episode = as.numeric(episode), 
    baker = str_to_lower(str_trim(baker))  
  )
```

use `anti_join()` to compare three datasets


```{r}
anti_join(bakes_df, results_df, by = c("series", "episode", "baker"))
anti_join(results_df, bakes_df, by = c("series", "episode", "baker"))
anti_join(bakers_df, bakes_df, by = c("baker", "series"))
anti_join(bakes_df, bakers_df, by = c("baker", "series"))
anti_join(results_df, bakers_df, by = c("series", "baker"))
anti_join(bakers_df, results_df, by = c("series","baker"))
```
I found out that Jo is actually Joanne, then I change it. 


merge all three
```{r}
final_df = results_df |>
  left_join(bakes_df, by = c("series", "episode", "baker")) |>
  left_join(bakers_df, by = c("series", "baker")) 
```





star bakers and winners from series 5 to 10
```{r}
star_bakers = final_df |> 
  filter(series >= 5 & series <= 10) |> 
  filter(result == "STAR BAKER" | result == "WINNER") |> 
  select(series, episode, baker, result)

star_bakers
```

From series 5 to 10, the all the winners are from episode 10. 

load and clean the viewership data 

```{r}
viewers_df = read_csv("./data/viewers.csv", na = c("NA", ".", "", "N/A")) |> 
  janitor::clean_names()

tidy_viewers_df = viewers_df |> 
  pivot_longer(
    cols = starts_with("series"),  
    names_to = "season",  
    values_to = "viewers",  
     names_prefix = "series_" 
  ) |> 
  mutate(
    season = as.numeric(season) 
  )

head(tidy_viewers_df, 10)
```
the avg viewers in series 1

```{r}

avg_viewers_season_1 <- tidy_viewers_df |> 
  filter(season == 1) |>  
  summarise(avg_viewers = mean(viewers, na.rm = TRUE))
  avg_viewers_season_1
```

```{r}

avg_viewers_season_5 <- tidy_viewers_df |> 
  filter(season == 5) |>  
  summarise(avg_viewers = mean(viewers, na.rm = TRUE))
  avg_viewers_season_5
  
```
The average viewership in Season 1 is `r avg_viewers_season_1` 
The average viewership in Season 5 is `r avg_viewers_season_5` 